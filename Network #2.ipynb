{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\777\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:CPU:0\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "for device in device_lib.list_local_devices(): print(device.name)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "letters = 'abcdefghjklmnop'\n",
    "\n",
    "def make_number(string):\n",
    "    number = letters.find(string[0]) * 15 + int(string[1:]) - 1\n",
    "    return number\n",
    "\n",
    "def make_string(number):\n",
    "    string = letters[number // 15] + str((number % 15) + 1)\n",
    "    return string\n",
    "\n",
    "def generator(games, batch_size = 64):\n",
    "    while(1):\n",
    "        count = 0\n",
    "        number = 0\n",
    "        positions = []\n",
    "        moves = []\n",
    "        for game in games:\n",
    "            position = [0] * 225\n",
    "            game = game.split(\" \")\n",
    "            if (game[0] == 'black'):\n",
    "                for i in range(1, len(game)):\n",
    "                    move = make_number(game[i])\n",
    "                    if (i % 2) == 1:\n",
    "                        positions.append(position.copy())\n",
    "                        moves.append(move)\n",
    "                        position[move] = 1\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        position[move] = -1\n",
    "                    if (count == batch_size):\n",
    "                        yield np.array(positions).reshape((batch_size, 15, 15, 1)), keras.utils.to_categorical(moves, 225)\n",
    "                        number += 1\n",
    "                        count = 0;\n",
    "                        positions = []\n",
    "                        moves = []\n",
    "            elif (game[0] == 'white'):\n",
    "                for i in range(1, len(game)):\n",
    "                    move = make_number(game[i])\n",
    "                    if (i % 2) == 0:\n",
    "                        positions.append(position.copy())\n",
    "                        moves.append(move)\n",
    "                        position[move] = -1\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        position[move] = 1\n",
    "                    if (count == batch_size):\n",
    "                        yield np.array(positions).reshape((batch_size, 15, 15, 1)), keras.utils.to_categorical(moves, 225)\n",
    "                        number += 1\n",
    "                        count = 0;\n",
    "                        positions = []\n",
    "                        moves = []\n",
    "\n",
    "data1 = np.array(pd.read_csv('train-1.renju'))\n",
    "#data2 = np.array(pd.read_csv('train-2.renju'))\n",
    "data = data1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\777\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\777\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 15, 15, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 15, 15, 64)   640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 15, 15, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 15, 15, 64)   256         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 15, 64)   36928       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 15, 15, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 15, 15, 64)   16448       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 15, 15, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 15, 15, 64)   256         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 15, 15, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 128)  73856       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 15, 15, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 128)  65664       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 15, 15, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 128)  8320        merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 15, 15, 128)  512         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 15, 15, 128)  0           conv2d_4[0][0]                   \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 128)  147584      merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 15, 15, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 128)  65664       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 15, 15, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 15, 15, 128)  512         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 15, 15, 128)  0           merge_2[0][0]                    \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 256)  295168      merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 15, 15, 256)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 256)  262400      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 15, 15, 256)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 256)  33024       merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 256)  1024        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "merge_4 (Merge)                 (None, 15, 15, 256)  0           conv2d_9[0][0]                   \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 15, 256)  590080      merge_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 15, 15, 256)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 15, 256)  262400      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 15, 15, 256)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 256)  1024        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merge_5 (Merge)                 (None, 15, 15, 256)  0           merge_4[0][0]                    \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 15, 15, 1)    257         merge_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 15, 15, 1)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 225)          0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 225)          0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,862,017\n",
      "Trainable params: 1,860,225\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\777\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.layers import BatchNormalization, Convolution2D, Input, merge, LeakyReLU\n",
    "from keras.layers.core import Activation, Layer\n",
    "\n",
    "def conv_block_3(feat_maps_out, prev):\n",
    "    prev = Conv2D(feat_maps_out, (3, 3), padding='same')(prev) \n",
    "    prev = LeakyReLU()(prev)\n",
    "    prev = Conv2D(feat_maps_out, (2, 2), padding='same')(prev) \n",
    "    prev = LeakyReLU()(prev)\n",
    "    prev = BatchNormalization(axis=3)(prev)\n",
    "    return prev\n",
    "\n",
    "def conv_block_5(feat_maps_out, prev):\n",
    "    prev = Conv2D(feat_maps_out, (5, 5), padding='same')(prev) \n",
    "    prev = LeakyReLU()(prev)\n",
    "    prev = Conv2D(feat_maps_out, (3, 3), padding='same')(prev) \n",
    "    prev = LeakyReLU()(prev)\n",
    "    prev = BatchNormalization(axis=3)(prev)\n",
    "    return prev\n",
    "\n",
    "def skip_block(feat_maps_in, feat_maps_out, prev):\n",
    "    if feat_maps_in != feat_maps_out:\n",
    "        prev = Conv2D(feat_maps_out, (1, 1), padding='same')(prev)\n",
    "    return prev \n",
    "\n",
    "def Residual_3(feat_maps_in, feat_maps_out, prev_layer):\n",
    "    skip = skip_block(feat_maps_in, feat_maps_out, prev_layer)\n",
    "    conv = conv_block_3(feat_maps_out, prev_layer)\n",
    "    return merge([skip, conv], mode='sum')\n",
    "\n",
    "def Residual_5(feat_maps_in, feat_maps_out, prev_layer):\n",
    "    skip = skip_block(feat_maps_in, feat_maps_out, prev_layer)\n",
    "    conv = conv_block_5(feat_maps_out, prev_layer)\n",
    "    return merge([skip, conv], mode='sum')\n",
    "\n",
    "img_rows = 15 \n",
    "img_cols = 15 \n",
    "\n",
    "inp = Input((img_rows, img_cols, 1))\n",
    "cnv1 = Conv2D(64, (3, 3), padding='same')(inp)\n",
    "cnv1 = LeakyReLU()(cnv1)\n",
    "cnv1 = BatchNormalization(axis=3)(cnv1)\n",
    "r1 = Residual_3(64, 64, cnv1)\n",
    "r2 = Residual_3(64, 128, r1)\n",
    "r3 = Residual_3(128, 128, r2)\n",
    "r4 = Residual_3(128, 256, r3)\n",
    "r5 = Residual_3(256, 256, r4)\n",
    "cnv2 = Conv2D(1, (1, 1), padding='same')(r5)\n",
    "cnv2 = LeakyReLU()(cnv2)\n",
    "cnv2 = Flatten()(cnv2)\n",
    "out = Activation('softmax')(cnv2)\n",
    "model = Model(input=inp, output=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 25625/562500 [>.............................] - ETA: 5:31:36 - loss: 1.9777 - acc: 0.4384"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator(data), steps_per_epoch = 36000000 / 64, epochs = 1)\n",
    "model.save('model-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
